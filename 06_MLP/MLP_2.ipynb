{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "FaadnhbpCcsh"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ly7lrx-gCuLy"
   },
   "source": [
    "## Dades\n",
    "\n",
    "Emprarem el dataset **Fashion MNIST**, una versió del conegut MNIST creat per l'empresa de venta de roba online _Zalando_. Conté dos conjunts de dades (un d'entrenament i un de test) amb 60000 i 10000 mostres respectivament.\n",
    "\n",
    "Cada un dels elements del dataset és una imatge de 28x28 pixels i pot ser de 10 categories diferents.\n",
    "\n",
    "La cárrega i preparació de les dades segueix la mateixa estructura que quan feiem aprenentatge emprant SVM, afegint una passa més, la creació de subconjunts d'entrenament (també coneguts com _mini-batches_).\n",
    "\n",
    "1. Carrega de dades.\n",
    "2. Estandarització.\n",
    "3. Creació de grups d'entrenament.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "PwSoPhjXCvV9"
   },
   "outputs": [],
   "source": [
    "etiquetes = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "# Definim una seqüència (composició) de transformacions \n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) # mitjana, desviacio tipica (precalculats)\n",
    "    ])\n",
    "\n",
    "# Descarregam un dataset ja integrat en la llibreria Pytorch\n",
    "train = datasets.FashionMNIST('../data', train=True, download=True, transform=transform)\n",
    "test = datasets.FashionMNIST('../data', train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-vdST97JpfB"
   },
   "source": [
    "Es molt important entendre com és l'estructura dels conjunts que necessitam per fer feina amb la xarxa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "EHy3Yd6C87Fz"
   },
   "outputs": [],
   "source": [
    "train_batch_size = 64\n",
    "test_batch_size = 100\n",
    "\n",
    "# Transformam les dades en l'estructura necessaria per entrenar una xarxa\n",
    "train_loader = torch.utils.data.DataLoader(train, train_batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test, test_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmCCiKz29MOe"
   },
   "source": [
    "\n",
    "A continuació cream un iterador sobre el nostre conjunt d'entrenament, això ens torna un _batch_. Mostram la primera imatge juntament amb la seva etiqueta. Després mostram informació referent al _batch_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "yispMZfr1bJn"
   },
   "outputs": [],
   "source": [
    "iterador =  iter(train_loader) # Un iterador!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "He-cj6JuFsgr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________\n",
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features, labels = next(iterador)\n",
    "\n",
    "\n",
    "image = features.numpy()[0].squeeze()\n",
    "plt.figure(figsize=[6,4])\n",
    "plt.imshow(image,cmap=\"gray\")\n",
    "plt.title(etiquetes[int(labels[0])])\n",
    "# TODO: mostrar una imatge del batch i com a títol posar l'etiqueta.\n",
    "# Extra: mostrar una graella amb tot el batch·\n",
    "\n",
    "print(\"_\"*50)\n",
    "print(f\"Feature batch shape: {features.size()}\")\n",
    "print(f\"Labels batch shape: {labels.size()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8i4Mg8KuD3r"
   },
   "source": [
    "## Definició de la xarxa\n",
    "Emprant el mòdul `nn` de _Pytorch_ podem definir la nostra pròpia classe. Com a mínim hi definirem dos mètodes:\n",
    "\n",
    "  - Constructor: mètode `__init__` en el que definim les capes de la nostra xarxa.\n",
    "  - `forward`: mètode en el que definim com és el fluxe de la informació. Aquí podem afegir capes no entrenables.\n",
    "\n",
    "La xarxa que heu de crear és una xarxa densa, per tant totes les capes seràn linears: `nn.Linear`. On la darrera capa ha de tenir una dimensionalitat igual al nombre de classes.\n",
    "\n",
    "Com a sortida és recomanable usar la funció _softmax_ que converteix un vector de $K$ nombres reals en una distribució de probabilitat de $K$ possibles resultats. És una generalització de la funció logística a múltiples dimensions, i s'utilitza en regressió logística multinomial. La funció softmax s'utilitza sovint com l'última funció d'activació d'una xarxa neuronal per normalitzar la sortida d'una xarxa a una distribució de probabilitat sobre classes de sortida predites. Es calcula de la següent manera:\n",
    "\n",
    "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/ab3ef6ba51afd36c1d2baf06540022053b2dca73\"\n",
    "     alt=\"Softmax\"\n",
    "     style=\"float: left; margin-right: 10px;\" />\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "Bz9rSkjSuF6r"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.l1 = nn.Linear(28*28,14*14)\n",
    "        self.l2 = nn.Linear(14*14,7*7)\n",
    "        self.l3 = nn.Linear(7*7,10)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "            \n",
    "        x = torch.flatten(x,1) # TODO: comprovar l'atribut shape de x un cop fet flatten\n",
    "        x = self.l1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.l3(x)\n",
    "        # TODO connectar les capes. El valor de retorn d'una cap és l'entrada de la següent\n",
    "        output = F.softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6ISOL_hCk7g"
   },
   "source": [
    "## Entrenament\n",
    "\n",
    "Les bones pràctiques de programació ens diuen que cal organitzar el codi en funcions. En definirem una per la passa d'entrenament i una altra per la fase de test.\n",
    "\n",
    "En aquesta fase s'ha de definir la funció de pèrdua, recordau que aquesta és la funció que avalua la diferència entre el que ha predit la xarxa i la sortida desitjada. Existeixen múltiples funcions de pèrdua que emprarem segons el problema a resoldre i les seves particularitats. Per exemple en el problema de regressió de la setmana passada vàrem emprar l'error absolut al quadrat (_MSE_).\n",
    "\n",
    "Nosaltres emprarem: **cross entropy** que prové de la teoria de la informació de _Shannon_ i que vé a explicar que l'entropia d'una variable aleatòria és el nivell mitjà d'informació / sorpresa / incertesa\" inherent als possibles resultats d'aquesta variable. La fórmula és la següent:\n",
    "\n",
    "$ LCE = -∑_{i=1}^M t_i \\log(p_i)$\n",
    "\n",
    "On $M$ és el nombre de classes, $t_i$ és un valor binari indicant si l'observació és d'aquesta classe (valor 1 si ho és i valor 0 en cas contrari) i $p_i$ és el resultat de la funció _Softmax_ per aquesta classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "h9OLtpPzClch"
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, log_interval=100, verbose=True):\n",
    "    \n",
    "    model.train() # Posam la xarxa en mode entrenament\n",
    "\n",
    "    loss_v = 0 # Per calcular la mitjana (és la vostra)\n",
    "\n",
    "    # Bucle per entrenar cada un dels batch\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    \n",
    "        data, target = data.to(device), target.to(device) \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "\n",
    "        loss = F.cross_entropy(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        ## Informació de debug\n",
    "        if batch_idx % log_interval == 0 and verbose:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Average: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item(), loss.item()/ len(data)))\n",
    "        loss_v += loss.item()\n",
    "\n",
    "    loss_v /= len(train_loader.dataset)\n",
    "    print('\\nTrain set: Average loss: {:.4f}\\n'.format(loss_v))\n",
    " \n",
    "    return loss_v\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval() # Posam la xarxa en mode avaluació\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output,target)\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # index amb la max probabilitat\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    " \n",
    "    # Informació de debug\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBGKL43vsUnD"
   },
   "source": [
    "A continuació definim els paràmetres d'entrenament i el bucle principal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "cNIBWqAwsVSb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.301336, Average: 0.035958\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 2.297276, Average: 0.035895\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 2.287128, Average: 0.035736\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 2.282120, Average: 0.035658\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 2.242531, Average: 0.035040\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 2.178586, Average: 0.034040\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 2.196684, Average: 0.034323\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 2.120987, Average: 0.033140\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 2.082247, Average: 0.032535\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 1.942693, Average: 0.030355\n",
      "\n",
      "Train set: Average loss: 0.0343\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0197, Accuracy: 5611/10000 (56%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.052661, Average: 0.032073\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.964893, Average: 0.030701\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.895906, Average: 0.029624\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.917894, Average: 0.029967\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.857515, Average: 0.029024\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.856521, Average: 0.029008\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.880756, Average: 0.029387\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 1.872315, Average: 0.029255\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.863989, Average: 0.029125\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 1.806796, Average: 0.028231\n",
      "\n",
      "Train set: Average loss: 0.0294\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0184, Accuracy: 6345/10000 (63%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.893510, Average: 0.029586\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 1.873685, Average: 0.029276\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 1.799730, Average: 0.028121\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 1.838517, Average: 0.028727\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.805897, Average: 0.028217\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.819955, Average: 0.028437\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.838260, Average: 0.028723\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 1.828091, Average: 0.028564\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.808028, Average: 0.028250\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 1.794281, Average: 0.028036\n",
      "\n",
      "Train set: Average loss: 0.0285\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0180, Accuracy: 6954/10000 (70%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.819537, Average: 0.028430\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 1.811438, Average: 0.028304\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 1.740332, Average: 0.027193\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 1.796991, Average: 0.028078\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1.771075, Average: 0.027673\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1.776680, Average: 0.027761\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 1.802074, Average: 0.028157\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 1.791600, Average: 0.027994\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1.778562, Average: 0.027790\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 1.757055, Average: 0.027454\n",
      "\n",
      "Train set: Average loss: 0.0277\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0175, Accuracy: 7250/10000 (72%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.734829, Average: 0.027107\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 1.765306, Average: 0.027583\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 1.675630, Average: 0.026182\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 1.769740, Average: 0.027652\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1.740379, Average: 0.027193\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 1.759167, Average: 0.027487\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1.777299, Average: 0.027770\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 1.772022, Average: 0.027688\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 1.783318, Average: 0.027864\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 1.746638, Average: 0.027291\n",
      "\n",
      "Train set: Average loss: 0.0272\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0173, Accuracy: 7480/10000 (75%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.693070, Average: 0.026454\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 1.744435, Average: 0.027257\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 1.657640, Average: 0.025901\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 1.758781, Average: 0.027481\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 1.717987, Average: 0.026844\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 1.754918, Average: 0.027421\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 1.760735, Average: 0.027511\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 1.763826, Average: 0.027560\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 1.783355, Average: 0.027865\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 1.742812, Average: 0.027231\n",
      "\n",
      "Train set: Average loss: 0.0269\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0172, Accuracy: 7557/10000 (76%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 1.681383, Average: 0.026272\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 1.727062, Average: 0.026985\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 1.651751, Average: 0.025809\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 1.752380, Average: 0.027381\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 1.703025, Average: 0.026610\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 1.749475, Average: 0.027336\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 1.745688, Average: 0.027276\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 1.758249, Average: 0.027473\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 1.781118, Average: 0.027830\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 1.739813, Average: 0.027185\n",
      "\n",
      "Train set: Average loss: 0.0267\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0171, Accuracy: 7604/10000 (76%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 1.675732, Average: 0.026183\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 1.712648, Average: 0.026760\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 1.646074, Average: 0.025720\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 1.745223, Average: 0.027269\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 1.691953, Average: 0.026437\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 1.744679, Average: 0.027261\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 1.732745, Average: 0.027074\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 1.753483, Average: 0.027398\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 1.778527, Average: 0.027789\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 1.736427, Average: 0.027132\n",
      "\n",
      "Train set: Average loss: 0.0266\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0171, Accuracy: 7644/10000 (76%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 1.672182, Average: 0.026128\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 1.700908, Average: 0.026577\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 1.640140, Average: 0.025627\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 1.737131, Average: 0.027143\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 1.682434, Average: 0.026288\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 1.741058, Average: 0.027204\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 1.722856, Average: 0.026920\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 1.749923, Average: 0.027343\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 1.775548, Average: 0.027743\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 1.732921, Average: 0.027077\n",
      "\n",
      "Train set: Average loss: 0.0265\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0170, Accuracy: 7653/10000 (77%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 1.669076, Average: 0.026079\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 1.692949, Average: 0.026452\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 1.634729, Average: 0.025543\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 1.729330, Average: 0.027021\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 1.674923, Average: 0.026171\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 1.738276, Average: 0.027161\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 1.715247, Average: 0.026801\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 1.747382, Average: 0.027303\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 1.771780, Average: 0.027684\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 1.729737, Average: 0.027027\n",
      "\n",
      "Train set: Average loss: 0.0264\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0170, Accuracy: 7682/10000 (77%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 1.665891, Average: 0.026030\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 1.687673, Average: 0.026370\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 1.630106, Average: 0.025470\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 1.722237, Average: 0.026910\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 1.668711, Average: 0.026074\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 1.736169, Average: 0.027128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 1.708413, Average: 0.026694\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 1.745694, Average: 0.027276\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 1.767514, Average: 0.027617\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 1.726157, Average: 0.026971\n",
      "\n",
      "Train set: Average loss: 0.0264\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0170, Accuracy: 7702/10000 (77%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 1.662372, Average: 0.025975\n",
      "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 1.683737, Average: 0.026308\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 1.626538, Average: 0.025415\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 1.716190, Average: 0.026815\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 1.662801, Average: 0.025981\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 1.734515, Average: 0.027102\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 1.700455, Average: 0.026570\n",
      "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 1.744225, Average: 0.027254\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 1.762511, Average: 0.027539\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 1.721833, Average: 0.026904\n",
      "\n",
      "Train set: Average loss: 0.0263\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0169, Accuracy: 7719/10000 (77%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 1.658608, Average: 0.025916\n",
      "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 1.680539, Average: 0.026258\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 1.623606, Average: 0.025369\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 1.711562, Average: 0.026743\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 1.657068, Average: 0.025892\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 1.733238, Average: 0.027082\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 1.691122, Average: 0.026424\n",
      "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 1.742798, Average: 0.027231\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 1.757553, Average: 0.027462\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 1.716704, Average: 0.026824\n",
      "\n",
      "Train set: Average loss: 0.0263\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0169, Accuracy: 7746/10000 (77%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 1.655157, Average: 0.025862\n",
      "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 1.677299, Average: 0.026208\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 1.621040, Average: 0.025329\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 1.707495, Average: 0.026680\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 1.651246, Average: 0.025801\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 1.731879, Average: 0.027061\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 1.682105, Average: 0.026283\n",
      "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 1.741402, Average: 0.027209\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 1.752957, Average: 0.027390\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 1.711241, Average: 0.026738\n",
      "\n",
      "Train set: Average loss: 0.0262\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0169, Accuracy: 7764/10000 (78%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 1.652058, Average: 0.025813\n",
      "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 1.674021, Average: 0.026157\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 1.618658, Average: 0.025292\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 1.704056, Average: 0.026626\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 1.645812, Average: 0.025716\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 1.730369, Average: 0.027037\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 1.675336, Average: 0.026177\n",
      "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 1.739975, Average: 0.027187\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 1.747856, Average: 0.027310\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 1.705712, Average: 0.026652\n",
      "\n",
      "Train set: Average loss: 0.0262\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0169, Accuracy: 7784/10000 (78%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 1.649033, Average: 0.025766\n",
      "Train Epoch: 15 [6400/60000 (11%)]\tLoss: 1.670770, Average: 0.026106\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 1.616553, Average: 0.025259\n",
      "Train Epoch: 15 [19200/60000 (32%)]\tLoss: 1.701082, Average: 0.026579\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 1.640321, Average: 0.025630\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 1.728622, Average: 0.027010\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 1.670270, Average: 0.026098\n",
      "Train Epoch: 15 [44800/60000 (75%)]\tLoss: 1.738503, Average: 0.027164\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 1.742265, Average: 0.027223\n",
      "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 1.699995, Average: 0.026562\n",
      "\n",
      "Train set: Average loss: 0.0262\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0169, Accuracy: 7794/10000 (78%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 1.645706, Average: 0.025714\n",
      "Train Epoch: 16 [6400/60000 (11%)]\tLoss: 1.667830, Average: 0.026060\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 1.614688, Average: 0.025229\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [134]\u001b[0m, in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Bucle d'entrenament\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, epochs):\n\u001b[1;32m---> 25\u001b[0m     train_l[epoch] \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     test_l[epoch]  \u001b[38;5;241m=\u001b[39m test(model, device, test_loader)\n",
      "Input \u001b[1;32mIn [133]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, device, train_loader, optimizer, epoch, log_interval, verbose)\u001b[0m\n\u001b[0;32m      5\u001b[0m loss_v \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;66;03m# Per calcular la mitjana (és la vostra)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Bucle per entrenar cada un dels batch\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     10\u001b[0m     data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device) \n\u001b[0;32m     12\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\.conda\\envs\\pyAA\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\.conda\\envs\\pyAA\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\.conda\\envs\\pyAA\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\.conda\\envs\\pyAA\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\.conda\\envs\\pyAA\\lib\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32m~\\.conda\\envs\\pyAA\\lib\\site-packages\\torchvision\\transforms\\transforms.py:93\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     90\u001b[0m         _log_api_usage_once(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms \u001b[38;5;241m=\u001b[39m transforms\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m     95\u001b[0m         img \u001b[38;5;241m=\u001b[39m t(img)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(33)\n",
    "\n",
    "# Ens permet emprar l'entorn de cuda. El podem activar a \"Entorno de ejecución\"\n",
    "use_cuda = False\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Paràmetres bàsics\n",
    "epochs = 50\n",
    "lr =  0.01 \n",
    "\n",
    "model = Net().to(device)\n",
    "\n",
    "# Stochastic gradient descent\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr) #momentum\n",
    "\n",
    "# Guardam el valor de pèrdua mig de cada època, per fer el gràfic final\n",
    "train_l = np.zeros((epochs))\n",
    "test_l = np.zeros((epochs))\n",
    "\n",
    "# Bucle d'entrenament\n",
    "for epoch in range(0, epochs):\n",
    "    train_l[epoch] = train(model, device, train_loader, optimizer, epoch)\n",
    "    test_l[epoch]  = test(model, device, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UFy6vECD8Pbq"
   },
   "outputs": [],
   "source": [
    "plt.title(\"Resultats de l'entrenament\")\n",
    "plt.plot(range(1, (epochs + 1)), train_l,  c=\"red\", label=\"train\")\n",
    "plt.plot(range(1,  (epochs + 1)), test_l,  c=\"green\", label=\"test\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5gFpefdQF6_"
   },
   "source": [
    "## SVM\n",
    "\n",
    "La pregunta és: Ho podem fer millor que una SVM lineal?\n",
    "\n",
    "### Preparació de les dades\n",
    "\n",
    "Aprofitam el dataset de _Pytorch_ per assegurar que volem resoldre el mateix problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ibF2ACMMO0O4"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjsxBaul0kCr"
   },
   "source": [
    "Transformam els tensors en matrius i donam el format adient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SYKUppOc_4JE",
    "outputId": "460e9e7e-e306-4856-ad44-56299c940acc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (10000, 784)\n",
      "(60000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "train_np = train.data.numpy()\n",
    "test_np = test.data.numpy()\n",
    "\n",
    "X_train = train_np.reshape((train_np.shape[0], train_np.shape[1]*train_np.shape[2]))\n",
    "y_train = train.targets.numpy()\n",
    "X_test = test_np.reshape((test_np.shape[0], test_np.shape[1]*test_np.shape[2]))\n",
    "y_test = test.targets.numpy()\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7uBkmemuh-4"
   },
   "source": [
    "La dimensionalitat és molt gran i no podriem resoldre el problema en un temps raonable, aplicarem un PCA per reduïr les característiques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "wYdM6Ctyu6EZ",
    "outputId": "cfa56866-90b2-445f-df9d-36a4dfcccae4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 187)\n",
      "(10000, 187)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA().fit(X_train)\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "\n",
    "pca = PCA(0.95, whiten=True)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "print(X_train_pca.shape)\n",
    "print(X_test_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vi901yuW00NY"
   },
   "source": [
    "Realitzam l'entrenament:\n",
    "\n",
    "**Nota**: La cerca de paràmetres no és massa adient...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D12v8YdlOyRc"
   },
   "outputs": [],
   "source": [
    "parameters = { 'C':[1]}\n",
    "svc = LinearSVC(max_iter=1500)\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(X_train_pca, y_train)\n",
    "y_predict = clf.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1-9HBkZ0_hB"
   },
   "source": [
    "Per poder fer comparacions directes mostram la mateixa mètrica que amb la xarxa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JIiWWoC3QCp8",
    "outputId": "be107954-402d-4023-b456-9bdd92ecdf26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8396\n"
     ]
    }
   ],
   "source": [
    "p = accuracy_score(y_predict, y_test)\n",
    "print(p)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
